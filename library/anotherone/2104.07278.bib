
@Article{         2104.07278,
  abstract      = {Markov chains are the de facto finite-state model for stochastic dynamical systems, and Markov decision processes (MDPs) extend Markov chains by incorporating non-deterministic behaviors. Given an MDP and rewards on states, a classical optimization criterion is the maximal expected total reward where the MDP stops after $T$ steps, which can be computed by a simple dynamic programming algorithm. We consider a natural generalization of the problem where the stopping times can be chosen according to a probability distribution, such that the expected stopping time is $T$, to optimize the expected total reward. Quite surprisingly we establish inter-reducibility of the expected stopping-time problem for Markov chains with the Positivity problem (which is related to the well-known Skolem problem), for which establishing either decidability or undecidability would be a major breakthrough. Given the hardness of the exact problem, we consider the approximate version of the problem: we show that it can be solved in exponential time for Markov chains and in exponential space for MDPs.},
  author        = {Krishnendu Chatterjee and Laurent Doyen},
  comments      = {A preliminary version will appear at LICS 2021},
  date-added    = {2021-05-02 11:42:06 +0200},
  date-modified = {2021-05-02 11:42:11 +0200},
  eprint        = {arXiv:2104.07278},
  eprinttype    = {arXiv},
  title         = {{S}tochastic {P}rocesses with {E}xpected {S}topping {T}ime},
  url           = {http://arxiv.org/abs/2104.07278},
  year          = {2021},
  bdsk-file-1   = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxASMjEwNC4wNzI3OCAtIGIucGRmTxEBOgAAAAABOgACAAADRVhUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEJEAAH/////EjIxMDQuMDcyNzggLSBiLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP////8AAAAAAAAAAAAAAAAAAQACAAAKAHhGAAAAAAAAAAAAAAAAAAhBcnRpY2xlcwACACkvOlZvbHVtZXM6RVhUOkFydGljbGVzOjIxMDQuMDcyNzggLSBiLnBkZgAADgAmABIAMgAxADAANAAuADAANwAyADcAOAAgAC0AIABiAC4AcABkAGYADwAIAAMARQBYAFQAEgAcL0FydGljbGVzLzIxMDQuMDcyNzggLSBiLnBkZgATAAwvVm9sdW1lcy9FWFT//wAAAAgADQAaACQAOQAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAF3},
  bdsk-url-1    = {http://arxiv.org/abs/2104.07278}
}
